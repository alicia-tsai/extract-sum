{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data\n",
    "import utils\n",
    "from main import extract_summary, report_rouge_scores\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cornell Newsroom Summarization Dataset\n",
    "\n",
    "Data are donwloaded from the [cornell newsroom summarization dataset](https://summari.es/). We are using the development set. We select *extractive* for our task and only include data that has 5 or more sentences in the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert newsroom jason file (dev.jsonl) to csv file (uncomment and run the code if 'news_dev.csv' is not available)\n",
    "# data.newsroom_json2csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of articles: 2566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>reference</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORKERS' ONLY REGRET WAS STAYING HOME</td>\n",
       "      <td>As many black men marched on Washington yester...</td>\n",
       "      <td>This story was reported by: NICK CHARLES, AUST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music review: Jake Bugg at the House of Blues</td>\n",
       "      <td>As the lights went down at the nearly sold-out...</td>\n",
       "      <td>As the lights went down at the nearly sold-out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HELP IS URGED FOR 36,000 HOMELESS IN CITY'S ST...</td>\n",
       "      <td>A yearlong study by the Community Service Soci...</td>\n",
       "      <td>A yearlong study by the Community Service Soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broadway - An early contender for 1982-83 - 'I...</td>\n",
       "      <td>THE new Broadway season is barely out of the s...</td>\n",
       "      <td>THE new Broadway season is barely out of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIRCUS FINDS ARENA GOOD PLACE TO PLAY</td>\n",
       "      <td>EAST RUTHERFORD YOUNGSTERS squealed with laugh...</td>\n",
       "      <td>EAST RUTHERFORD YOUNGSTERS squealed with laugh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0          NEW YORKERS' ONLY REGRET WAS STAYING HOME   \n",
       "1      Music review: Jake Bugg at the House of Blues   \n",
       "2  HELP IS URGED FOR 36,000 HOMELESS IN CITY'S ST...   \n",
       "3  Broadway - An early contender for 1982-83 - 'I...   \n",
       "4              CIRCUS FINDS ARENA GOOD PLACE TO PLAY   \n",
       "\n",
       "                                           reference  \\\n",
       "0  As many black men marched on Washington yester...   \n",
       "1  As the lights went down at the nearly sold-out...   \n",
       "2  A yearlong study by the Community Service Soci...   \n",
       "3  THE new Broadway season is barely out of the s...   \n",
       "4  EAST RUTHERFORD YOUNGSTERS squealed with laugh...   \n",
       "\n",
       "                                                text  \n",
       "0  This story was reported by: NICK CHARLES, AUST...  \n",
       "1  As the lights went down at the nearly sold-out...  \n",
       "2  A yearlong study by the Community Service Soci...  \n",
       "3  THE new Broadway season is barely out of the s...  \n",
       "4  EAST RUTHERFORD YOUNGSTERS squealed with laugh...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('../data/newsroom/news_dev.csv')\n",
    "print('# of articles:', len(news))\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "\n",
    "- Summarization algorithms includes: \n",
    "    - SMRS (TF-IDF matrix)\n",
    "    - Franke-Wolfe (TF-IDF matrix)\n",
    "    - Franke-Wolfe (Sentence embeddings matrix)\n",
    "- *Matlab* and *Python for matlab engine* is required to run the SMRS method. Remove `'SMRS'` from the `methods` list below if matlab is not installed.\n",
    "\n",
    "- Main function: `extract_summary()`\n",
    "\n",
    "```python\n",
    "# Arguments:\n",
    "#     - doc: string; article body text\n",
    "#     - ref: string; reference summary\n",
    "#     - title: string; title of the article\n",
    "#     - k: number of extracted examplars\n",
    "#     - print_summary: print summary text for each algorithm\n",
    "#     - report_rouge: report rouge score (need to pass in ref argument)\n",
    "#     - rouge_embed: use word embedding to calculate rouge score\n",
    "#     - vectorize_scores: return scores in np.ndarray instead of in a dictionary\n",
    "#     - methods: summarization algorithms to be used\n",
    "# Return:\n",
    "#     - summary: dictionary; extracted summary sentences using each algorithm\n",
    "#     - word_count: dictionary; number of words in the extracted summary\n",
    "#     - runtime: computation time of each algorithm\n",
    "#     - scores: rouge score of each algorithm\n",
    "        \n",
    "summary, word_count, runtime, scores = extract_summary(doc, ref=None, title=None, k=5, print_summary=False, \n",
    "                                                       report_rouge=False, print_rouge=True, rouge_embed=False, \n",
    "                                                       vectorize_scores=False, methods=['random', 'SMRS', 'tfidf', 'embed']);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of titles, reference summaries, and body text\n",
    "news_titles, news_refs, news_text = data.get_newsroom_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentence: 27, # vocab: 400\n",
      "# of selected exemplar: 5\n",
      "\n",
      "Title: HELP IS URGED FOR 36,000 HOMELESS IN CITY'S STREETS\n",
      "\n",
      "=============== Referecne Text ==============\n",
      "A yearlong study by the Community Service Society of New York has concluded that the problem of homeless people on the streets of the city has ''reached such extraordinary proportions'' that emergency housing must be set up.   The study, to be made public tomorrow, says government agencies have failed to face the problem of the homeless and have made it even worse with the state's program of discharging many patients from mental institutions into communities.   The homeless are found in almost every part of the city. Sometimes they are seen shuffling along the streets or crouched in doorways seeking temporary shelter from wind and rain. They inhabit the bus and railroad stations and subways until they are chased away by the police.\n",
      "-----\n",
      "Word count:122\n",
      "\n",
      "========== Extracted summary: SMRS ==========\n",
      "Poignant scene at garbage can. Sometimes they are seen shuffling along the streets or crouched in doorways seeking temporary shelter from wind and rain. With her hands folded, because she 'had no place to go nights.' she said she had had such bad luck and that with rents so high, she couldn't afford both a place to stay and food to eat. ''they think there is no end to revenues.''  mr. In some cases, they said, buildings had been burned down to drive out tenants\n",
      "-----\n",
      "Word count:85\n",
      "SMRS computation time: 0.379\n",
      "\n",
      "========== Extracted summary: Tfidf ==========\n",
      "Report rebuts 'myth'  ''counter to the prevailing myth that the homeless choose their nomadic lifestyle and refuse any assistance offered them,'' the report says, ''the reality is that most have never been offered the fundamental provisions of decent food and humane, noncoercive shelter.''  the report, ''private lives/ public spaces: homeless adults on the streets of new york city,'' was the result of hundreds of interviews by two researchers, ellen baxter and kim hopper, who sought out the homeless all over the city, finding a widely varied group. ''there are some people who choose not to come to the shelters,'' he said. She picks up a social security check at the bank each month, but it is barely enough to get by on.''  the report says that mental patients released from hospitals under a state program that seeks to ease them into communities constitute another part of the problem. In some cases, they said, buildings had been burned down to drive out tenants.  the homeless are found in almost every part of the city\n",
      "-----\n",
      "Word count:173\n",
      "Tfidf computation time: 0.004\n",
      "\n",
      "====== Extracted summary: sentence embeddings ======\n",
      " the homeless are found in almost every part of the city. They inhabit the bus and railroad stations and subways until they are chased away by the police.  ''advocacy groups do not think there is any limit on the amount of money government can spend,'' he said. With her hands folded, because she 'had no place to go nights.' she said she had had such bad luck and that with rents so high, she couldn't afford both a place to stay and food to eat. Poignant scene at garbage can\n",
      "-----\n",
      "Word count:90\n",
      "Sentence embedding computation time: 0.001\n"
     ]
    }
   ],
   "source": [
    "doc_idx = 2\n",
    "doc = news_text[doc_idx]\n",
    "ref = news_refs[doc_idx]\n",
    "title = news_titles[doc_idx]\n",
    "\n",
    "k=5\n",
    "methods = ['SMRS', 'tfidf', 'embed']\n",
    "extract_summary(doc, ref, title, k=k, report_rouge=False, methods=methods, print_summary=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.289\n",
      "Overlap 1-gram \t\t\tPrecision: 0.315\n",
      "Overlap 1-gram \t\t\tRecall: 0.267\n",
      "Overlap bi-gram \t\tF1: 0.182\n",
      "Overlap bi-gram \t\tPrecision: 0.212\n",
      "Overlap bi-gram \t\tRecall: 0.159\n",
      "Longest Common Subsequence \tF1: 0.286\n",
      "Longest Common Subsequence \tPrecision: 0.315\n",
      "Longest Common Subsequence \tRecall: 0.267\n",
      "\n",
      "tfidf\n",
      "Overlap 1-gram \t\t\tF1: 0.290\n",
      "Overlap 1-gram \t\t\tPrecision: 0.242\n",
      "Overlap 1-gram \t\t\tRecall: 0.360\n",
      "Overlap bi-gram \t\tF1: 0.114\n",
      "Overlap bi-gram \t\tPrecision: 0.096\n",
      "Overlap bi-gram \t\tRecall: 0.142\n",
      "Longest Common Subsequence \tF1: 0.218\n",
      "Longest Common Subsequence \tPrecision: 0.195\n",
      "Longest Common Subsequence \tRecall: 0.291\n",
      "\n",
      "embed\n",
      "Overlap 1-gram \t\t\tF1: 0.365\n",
      "Overlap 1-gram \t\t\tPrecision: 0.397\n",
      "Overlap 1-gram \t\t\tRecall: 0.337\n",
      "Overlap bi-gram \t\tF1: 0.267\n",
      "Overlap bi-gram \t\tPrecision: 0.303\n",
      "Overlap bi-gram \t\tRecall: 0.239\n",
      "Longest Common Subsequence \tF1: 0.348\n",
      "Longest Common Subsequence \tPrecision: 0.384\n",
      "Longest Common Subsequence \tRecall: 0.326\n",
      "CPU times: user 8.76 s, sys: 429 ms, total: 9.19 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_summary(doc, ref, title, k=k, report_rouge=True, rouge_embed=False, \n",
    "                methods=methods, print_summary=False, print_rouge=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.742\n",
      "Overlap 1-gram \t\t\tPrecision: 0.777\n",
      "Overlap 1-gram \t\t\tRecall: 0.710\n",
      "Overlap bi-gram \t\tF1: 0.793\n",
      "Overlap bi-gram \t\tPrecision: 0.809\n",
      "Overlap bi-gram \t\tRecall: 0.778\n",
      "Longest Common Subsequence \tF1: 0.758\n",
      "Longest Common Subsequence \tPrecision: 0.836\n",
      "Longest Common Subsequence \tRecall: 0.710\n",
      "\n",
      "tfidf\n",
      "Overlap 1-gram \t\t\tF1: 0.748\n",
      "Overlap 1-gram \t\t\tPrecision: 0.726\n",
      "Overlap 1-gram \t\t\tRecall: 0.771\n",
      "Overlap bi-gram \t\tF1: 0.794\n",
      "Overlap bi-gram \t\tPrecision: 0.780\n",
      "Overlap bi-gram \t\tRecall: 0.808\n",
      "Longest Common Subsequence \tF1: 0.577\n",
      "Longest Common Subsequence \tPrecision: 0.518\n",
      "Longest Common Subsequence \tRecall: 0.771\n",
      "\n",
      "embed\n",
      "Overlap 1-gram \t\t\tF1: 0.766\n",
      "Overlap 1-gram \t\t\tPrecision: 0.803\n",
      "Overlap 1-gram \t\t\tRecall: 0.732\n",
      "Overlap bi-gram \t\tF1: 0.820\n",
      "Overlap bi-gram \t\tPrecision: 0.838\n",
      "Overlap bi-gram \t\tRecall: 0.803\n",
      "Longest Common Subsequence \tF1: 0.782\n",
      "Longest Common Subsequence \tPrecision: 0.862\n",
      "Longest Common Subsequence \tRecall: 0.732\n",
      "CPU times: user 1min 34s, sys: 3.92 s, total: 1min 38s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_summary(doc, ref, title, k=k, report_rouge=True, rouge_embed=True, \n",
    "                methods=methods, print_summary=False, print_rouge=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE Score Across Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "start = 20\n",
    "num_articles = 20\n",
    "articles = news_text[start : start + num_articles]\n",
    "references = news_refs[start : start + num_articles]\n",
    "titles = news_titles[start : start + num_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Mean ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMRS</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.179161</td>\n",
       "      <td>0.250885</td>\n",
       "      <td>0.251754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.323557</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.461760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.153440</td>\n",
       "      <td>0.243489</td>\n",
       "      <td>0.187242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.090849</td>\n",
       "      <td>0.102822</td>\n",
       "      <td>0.147635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.151322</td>\n",
       "      <td>0.111961</td>\n",
       "      <td>0.284388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.078691</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.106724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.150810</td>\n",
       "      <td>0.221773</td>\n",
       "      <td>0.198754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>0.320464</td>\n",
       "      <td>0.262709</td>\n",
       "      <td>0.450307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.151265</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.183257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.591946</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.002086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>43.550000</td>\n",
       "      <td>110.200000</td>\n",
       "      <td>41.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SMRS       tfidf      embed\n",
       "1-gram F1                  0.179161    0.250885   0.251754\n",
       "1-gram Precision           0.323557    0.283636   0.461760\n",
       "1-gram Recall              0.153440    0.243489   0.187242\n",
       "bi-gram F1                 0.090849    0.102822   0.147635\n",
       "bi-gram Precision          0.151322    0.111961   0.284388\n",
       "bi-gram Recall             0.078691    0.100405   0.106724\n",
       "longest common F1          0.150810    0.221773   0.198754\n",
       "longest common Precision   0.320464    0.262709   0.450307\n",
       "longest common Recall      0.151265    0.225166   0.183257\n",
       "runtime                    0.591946    0.008317   0.002086\n",
       "word count                43.550000  110.200000  41.950000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 19s, sys: 9.84 s, total: 3min 29s\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rouge_mean, rouge_median, rouge_std = report_rouge_scores(articles, references, titles, k, methods=methods)\n",
    "\n",
    "index =  ['1-gram F1', '1-gram Precision', '1-gram Recall', 'bi-gram F1', 'bi-gram Precision', 'bi-gram Recall', \n",
    "          'longest common F1', 'longest common Precision', 'longest common Recall', 'runtime', 'word count']\n",
    "\n",
    "print('=' * 22 + ' Mean ' + '=' * 22)\n",
    "rouge_mean.index = index\n",
    "display(rouge_mean)\n",
    "\n",
    "# print('=' * 21 + ' Median ' + '=' * 21)\n",
    "# rouge_median.index = index\n",
    "# display(rouge_median)\n",
    "\n",
    "# print('=' * 15 + ' Standard Deviation ' + '=' * 15)\n",
    "# rouge_std.index = index\n",
    "# display(rouge_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding ROUGE Score Across Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Mean ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMRS</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.675342</td>\n",
       "      <td>0.719069</td>\n",
       "      <td>0.704342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.754768</td>\n",
       "      <td>0.727654</td>\n",
       "      <td>0.794987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.615283</td>\n",
       "      <td>0.714310</td>\n",
       "      <td>0.636428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.737543</td>\n",
       "      <td>0.780718</td>\n",
       "      <td>0.761497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.791181</td>\n",
       "      <td>0.787599</td>\n",
       "      <td>0.812032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.692878</td>\n",
       "      <td>0.775532</td>\n",
       "      <td>0.718319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.685582</td>\n",
       "      <td>0.686588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>1.676865</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>1.918299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.615283</td>\n",
       "      <td>0.714310</td>\n",
       "      <td>0.636428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.445395</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>47.800000</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>50.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SMRS       tfidf      embed\n",
       "1-gram F1                  0.675342    0.719069   0.704342\n",
       "1-gram Precision           0.754768    0.727654   0.794987\n",
       "1-gram Recall              0.615283    0.714310   0.636428\n",
       "bi-gram F1                 0.737543    0.780718   0.761497\n",
       "bi-gram Precision          0.791181    0.787599   0.812032\n",
       "bi-gram Recall             0.692878    0.775532   0.718319\n",
       "longest common F1          0.667800    0.685582   0.686588\n",
       "longest common Precision   1.676865    0.885565   1.918299\n",
       "longest common Recall      0.615283    0.714310   0.636428\n",
       "runtime                    0.445395    0.004235   0.001116\n",
       "word count                47.800000  135.800000  50.100000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 50s, sys: 49.6 s, total: 16min 39s\n",
      "Wall time: 17min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rouge_mean_embed, rouge_median_embed, rouge_std_embed = report_rouge_scores(articles, references, titles, k, \n",
    "                                                                            rouge_embed=True, methods=methods)\n",
    "\n",
    "print('=' * 22 + ' Mean ' + '=' * 22)\n",
    "rouge_mean_embed.index = index\n",
    "display(rouge_mean_embed)\n",
    "\n",
    "# print('=' * 21 + ' Median ' + '=' * 21)\n",
    "# rouge_median_embed.index = index\n",
    "# display(rouge_median_embed)\n",
    "\n",
    "# print('=' * 15 + ' Standard Deviation ' + '=' * 15)\n",
    "# rouge_std_embed.index = index\n",
    "# display(rouge_std_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
