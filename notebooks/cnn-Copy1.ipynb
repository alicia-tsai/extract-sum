{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data\n",
    "import utils\n",
    "from main import extract_summary, report_rouge_scores\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Get list of titles, reference summaries, and body text\n",
    "source_titles, source_refs, source_text = data.get_cnn_data(50)\n",
    "print(len(source_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization.textcleaner import clean_text_by_sentences\n",
    "from gensim.summarization.summarizer import _build_corpus, _build_hasheable_corpus, _set_graph_edge_weights\n",
    "from gensim.summarization.commons import build_graph, remove_unreachable_nodes\n",
    "from gensim.summarization.keywords import get_graph\n",
    "from gensim.summarization.pagerank_weighted import pagerank_weighted, build_adjacency_matrix\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "\n",
    "\n",
    "# hashable_corpus = _build_hasheable_corpus(_build_corpus(clean_text_by_sentences(source_text[0])))\n",
    "\n",
    "# graph = build_graph(hashable_corpus)\n",
    "# _set_graph_edge_weights(graph)\n",
    "#remove_unreachable_nodes(graph)\n",
    "#pagerank_scores = pagerank_weighted(graph)\n",
    "#pagerank_scores\n",
    "# coeff_adjacency_matrix = build_adjacency_matrix(graph)\n",
    "# matrix = coeff_adjacency_matrix.toarray()\n",
    "# damping=0.85\n",
    "# probabilities = (1 - damping) / float(len(graph))\n",
    "# matrix += probabilities\n",
    "#hashable_corpus.sort(key=lambda doc: pagerank_scores.get(doc, 0), reverse=True)\n",
    "#graph.nodes()\n",
    "#hashable_corpus\n",
    "\n",
    "# graph = get_graph(\"The road to hell is paved with good intentions.\")\n",
    "# result = pagerank_weighted(graph)\n",
    "# result\n",
    "#corpus = utils.split_sentence(source_text[0])\n",
    "corpus = [sen.token for sen in clean_text_by_sentences(source_text[0])]\n",
    "X = get_bm25_weights([s.split() for s in corpus])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sen.token for sen in clean_text_by_sentences(source_text[0])]\n",
    "source = [sen.text for sen in clean_text_by_sentences(source_text[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you're the venezuelan government, you take over a toilet paper factory.\n",
      "\n",
      "when you're running low on toilet paper and getting desperate, what do you do?\n",
      "\n",
      "the aim, he explained, is to review the \"production, marketing and distribution (of) toilet paper.\".\n",
      "\n",
      "by the \"people's defense,\" arreaza was referring to a government agency created on september 13 by president nicolas maduro to \"defeat the economic war that has been declared in the country,\" according to a report from state-run atv.\n",
      "\n",
      "at that time, fleming announced the country would import 50 million rolls of toilet paper to meet demand.\n",
      "\n",
      "on saturday, vice president jorge arreaza announced the \"temporary occupation\" of the paper manufacturing company's plant in the state of aragua.\n",
      "\n",
      "the bathroom essential is one of the basic goods and foodstuffs that have been disappearing from store shelves since earlier this year.\n",
      "\n",
      "other hygiene products, such as toothpaste and soap, may be similarly brought in bulk for the same reason, the minister said.\n",
      "\n",
      "they've also suggested the problem is tied to a broader conspiracy.\n",
      "\n",
      "these moves make it so many producers can't even break even, they say.\n",
      "\n",
      "scissors-wielding thieves attack women in venezuela.\n",
      "\n",
      "this group is charged with looking at inefficiencies across various industries in the nation, including foods and other products, and taking action presumably in the south american nation's best interests.\n",
      "\n",
      "as the amount of tp and other products, such as rice and cooking oil, have lagged, the blame game has picked up.\n",
      "\n",
      "in caracas, for instance, long lines are common whenever new rolls come in.\n",
      "\n",
      "businesses and the political opposition say the shortages stem from ill-conceived government policies such as price controls on basic goods and tight restrictions on foreign currency.\n",
      "\n",
      "\"there is no deficiency in production,\" commerce minister alejandro fleming said in may according to atv, \"but an excessive demand generating purchases by a nervous population because of a media campaign.\".\n",
      "\n",
      "but the government has said private companies aren't doing their part, accusing them of hoarding their products in hopes of selling it later at a higher price.\n",
      "\n",
      "people's defense from the economy will not allow hoarding or failures in the production and distribution of essential commodities,\" the vice president said.\n",
      "\n",
      "toilet paper is very much a part of the war.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import eig\n",
    "X = np.array(X)\n",
    "val, vec = eig(X)\n",
    "idx = np.argsort(-vec[:, 0])\n",
    "[print(source[i] + '\\n') for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx = 0\n",
    "doc = source_text[doc_idx]\n",
    "ref = source_refs[doc_idx]\n",
    "title = source_titles[doc_idx] if source_titles else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soruce Text: 19 sentences, 171 distinct vocab\n",
      "# of selected sentences: 4\n",
      "=============== Referecne Text ==============\n",
      "venezuela occupies paper manufacturing company's plant in aragua, vice president says. vp: nation won't \"allow hoarding or failures in the production and distribution\" of essentials. government accuses companies of hoarding, blames media for fanning fears. private firms says ill-conceived price control, currency policies have stifled production.\n",
      "-----\n",
      "Word count:46\n",
      "\n",
      "========== Extracted summary: First k ==========\n",
      "When you're running low on toilet paper and getting desperate, what do you do?\n",
      "If you're the venezuelan government, you take over a toilet paper factory.\n",
      "On saturday, vice president jorge arreaza announced the \"temporary occupation\" of the paper manufacturing company's plant in the state of aragua.\n",
      "The aim, he explained, is to review the \"production, marketing and distribution (of) toilet paper.\".\n",
      "-----\n",
      "Word count:62\n",
      "First_k selection computation time: 0.000\n",
      "\n",
      "========== Extracted summary: SMRS ==========\n",
      "Scissors-wielding thieves attack women in venezuela.\n",
      "They've also suggested the problem is tied to a broader conspiracy.\n",
      "These moves make it so many producers can't even break even, they say.\n",
      "In caracas, for instance, long lines are common whenever new rolls come in.\n",
      "-----\n",
      "Word count:43\n",
      "SMRS computation time: 0.375\n",
      "\n",
      "========== Extracted summary: TextRank ==========\n",
      "people's defense from the economy will not allow hoarding or failures in the production and distribution of essential commodities,\" the vice president said.\n",
      "by the \"people's defense,\" arreaza was referring to a government agency created on september 13 by president nicolas maduro to \"defeat the economic war that has been declared in the country,\" according to a report from state-run atv.\n",
      "but the government has said private companies aren't doing their part, accusing them of hoarding their products in hopes of selling it later at a higher price.\n",
      "at that time, fleming announced the country would import 50 million rolls of toilet paper to meet demand.\n",
      "Word count: 106\n",
      "TextRank computation time: 0.005\n",
      "\n",
      "========== Extracted summary: FWSR-BM25 ==========\n",
      "On saturday, vice president jorge arreaza announced the \"temporary occupation\" of the paper manufacturing company's plant in the state of aragua.\n",
      "This group is charged with looking at inefficiencies across various industries in the nation, including foods and other products, and taking action presumably in the south american nation's best interests.\n",
      "Businesses and the political opposition say the shortages stem from ill-conceived government policies such as price controls on basic goods and tight restrictions on foreign currency.\n",
      "\"there is no deficiency in production,\" commerce minister alejandro fleming said in may according to atv, \"but an excessive demand generating purchases by a nervous population because of a media campaign.\".\n",
      "-----\n",
      "Word count:108\n",
      "FWSR-BM25 computation time: 0.001\n",
      "\n",
      "====== Extracted summary: FWSR-SIF ======\n",
      "Sentence embedding shape: (19, 300)\n",
      "On saturday, vice president jorge arreaza announced the \"temporary occupation\" of the paper manufacturing company's plant in the state of aragua.\n",
      "\"the ... people's defense from the economy will not allow hoarding or failures in the production and distribution of essential commodities,\" the vice president said.\n",
      "In caracas, for instance, long lines are common whenever new rolls come in.\n",
      "Other hygiene products, such as toothpaste and soap, may be similarly brought in bulk for the same reason, the minister said.\n",
      "-----\n",
      "Word count:80\n",
      "FWSR-SIF computation time: 0.001\n",
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "first-k\n",
      "Overlap 1-gram \t\t\tF1: 0.217\n",
      "Overlap 1-gram \t\t\tPrecision: 0.200\n",
      "Overlap 1-gram \t\t\tRecall: 0.238\n",
      "Overlap bi-gram \t\tF1: 0.114\n",
      "Overlap bi-gram \t\tPrecision: 0.100\n",
      "Overlap bi-gram \t\tRecall: 0.133\n",
      "Longest Common Subsequence \tF1: 0.171\n",
      "Longest Common Subsequence \tPrecision: 0.160\n",
      "Longest Common Subsequence \tRecall: 0.190\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.095\n",
      "Overlap 1-gram \t\t\tPrecision: 0.095\n",
      "Overlap 1-gram \t\t\tRecall: 0.095\n",
      "Overlap bi-gram \t\tF1: 0.000\n",
      "Overlap bi-gram \t\tPrecision: 0.000\n",
      "Overlap bi-gram \t\tRecall: 0.000\n",
      "Longest Common Subsequence \tF1: 0.071\n",
      "Longest Common Subsequence \tPrecision: 0.071\n",
      "Longest Common Subsequence \tRecall: 0.071\n",
      "\n",
      "TextRank\n",
      "Overlap 1-gram \t\t\tF1: 0.248\n",
      "Overlap 1-gram \t\t\tPrecision: 0.190\n",
      "Overlap 1-gram \t\t\tRecall: 0.357\n",
      "Overlap bi-gram \t\tF1: 0.095\n",
      "Overlap bi-gram \t\tPrecision: 0.068\n",
      "Overlap bi-gram \t\tRecall: 0.156\n",
      "Longest Common Subsequence \tF1: 0.212\n",
      "Longest Common Subsequence \tPrecision: 0.190\n",
      "Longest Common Subsequence \tRecall: 0.357\n",
      "\n",
      "FWSR-BM25\n",
      "Overlap 1-gram \t\t\tF1: 0.241\n",
      "Overlap 1-gram \t\t\tPrecision: 0.176\n",
      "Overlap 1-gram \t\t\tRecall: 0.381\n",
      "Overlap bi-gram \t\tF1: 0.079\n",
      "Overlap bi-gram \t\tPrecision: 0.057\n",
      "Overlap bi-gram \t\tRecall: 0.133\n",
      "Longest Common Subsequence \tF1: 0.158\n",
      "Longest Common Subsequence \tPrecision: 0.143\n",
      "Longest Common Subsequence \tRecall: 0.310\n",
      "\n",
      "FWSR-SIF\n",
      "Overlap 1-gram \t\t\tF1: 0.288\n",
      "Overlap 1-gram \t\t\tPrecision: 0.242\n",
      "Overlap 1-gram \t\t\tRecall: 0.357\n",
      "Overlap bi-gram \t\tF1: 0.182\n",
      "Overlap bi-gram \t\tPrecision: 0.145\n",
      "Overlap bi-gram \t\tRecall: 0.244\n",
      "Longest Common Subsequence \tF1: 0.269\n",
      "Longest Common Subsequence \tPrecision: 0.242\n",
      "Longest Common Subsequence \tRecall: 0.357\n"
     ]
    }
   ],
   "source": [
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "extract_summary(doc, ref, title, report_rouge=True, print_rouge=True, methods=methods, print_summary=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "first-k\n",
      "Overlap 1-gram \t\t\tF1: 0.300\n",
      "Overlap 1-gram \t\t\tPrecision: 0.255\n",
      "Overlap 1-gram \t\t\tRecall: 0.364\n",
      "Overlap bi-gram \t\tF1: 0.065\n",
      "Overlap bi-gram \t\tPrecision: 0.054\n",
      "Overlap bi-gram \t\tRecall: 0.081\n",
      "Longest Common Subsequence \tF1: 0.283\n",
      "Longest Common Subsequence \tPrecision: 0.255\n",
      "Longest Common Subsequence \tRecall: 0.364\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.122\n",
      "Overlap 1-gram \t\t\tPrecision: 0.102\n",
      "Overlap 1-gram \t\t\tRecall: 0.152\n",
      "Overlap bi-gram \t\tF1: 0.000\n",
      "Overlap bi-gram \t\tPrecision: 0.000\n",
      "Overlap bi-gram \t\tRecall: 0.000\n",
      "Longest Common Subsequence \tF1: 0.114\n",
      "Longest Common Subsequence \tPrecision: 0.102\n",
      "Longest Common Subsequence \tRecall: 0.152\n",
      "\n",
      "TextRank\n",
      "Overlap 1-gram \t\t\tF1: 0.232\n",
      "Overlap 1-gram \t\t\tPrecision: 0.165\n",
      "Overlap 1-gram \t\t\tRecall: 0.394\n",
      "Overlap bi-gram \t\tF1: 0.014\n",
      "Overlap bi-gram \t\tPrecision: 0.010\n",
      "Overlap bi-gram \t\tRecall: 0.027\n",
      "Longest Common Subsequence \tF1: 0.180\n",
      "Longest Common Subsequence \tPrecision: 0.165\n",
      "Longest Common Subsequence \tRecall: 0.394\n",
      "\n",
      "FWSR-BM25\n",
      "Overlap 1-gram \t\t\tF1: 0.213\n",
      "Overlap 1-gram \t\t\tPrecision: 0.139\n",
      "Overlap 1-gram \t\t\tRecall: 0.455\n",
      "Overlap bi-gram \t\tF1: 0.043\n",
      "Overlap bi-gram \t\tPrecision: 0.027\n",
      "Overlap bi-gram \t\tRecall: 0.108\n",
      "Longest Common Subsequence \tF1: 0.138\n",
      "Longest Common Subsequence \tPrecision: 0.130\n",
      "Longest Common Subsequence \tRecall: 0.424\n",
      "\n",
      "FWSR-SIF\n",
      "Overlap 1-gram \t\t\tF1: 0.364\n",
      "Overlap 1-gram \t\t\tPrecision: 0.291\n",
      "Overlap 1-gram \t\t\tRecall: 0.485\n",
      "Overlap bi-gram \t\tF1: 0.078\n",
      "Overlap bi-gram \t\tPrecision: 0.061\n",
      "Overlap bi-gram \t\tRecall: 0.108\n",
      "Longest Common Subsequence \tF1: 0.305\n",
      "Longest Common Subsequence \tPrecision: 0.273\n",
      "Longest Common Subsequence \tRecall: 0.455\n",
      "CPU times: user 7.42 s, sys: 512 ms, total: 7.93 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k=5\n",
    "# ratio=0.3\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "extract_summary(doc, ref, title, report_rouge=True, rouge_embed=False, \n",
    "                methods=methods, print_summary=False, print_rouge=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Word Embedding ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "first-k\n",
      "Overlap 1-gram \t\t\tF1: 0.529\n",
      "Overlap 1-gram \t\t\tPrecision: 0.454\n",
      "Overlap 1-gram \t\t\tRecall: 0.634\n",
      "Overlap bi-gram \t\tF1: 0.627\n",
      "Overlap bi-gram \t\tPrecision: 0.541\n",
      "Overlap bi-gram \t\tRecall: 0.744\n",
      "Longest Common Subsequence \tF1: 0.289\n",
      "Longest Common Subsequence \tPrecision: 0.264\n",
      "Longest Common Subsequence \tRecall: 0.634\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.333\n",
      "Overlap 1-gram \t\t\tPrecision: 0.311\n",
      "Overlap 1-gram \t\t\tRecall: 0.358\n",
      "Overlap bi-gram \t\tF1: 0.497\n",
      "Overlap bi-gram \t\tPrecision: 0.489\n",
      "Overlap bi-gram \t\tRecall: 0.505\n",
      "Longest Common Subsequence \tF1: 0.274\n",
      "Longest Common Subsequence \tPrecision: 0.247\n",
      "Longest Common Subsequence \tRecall: 0.358\n",
      "\n",
      "TextRank\n",
      "Overlap 1-gram \t\t\tF1: 0.541\n",
      "Overlap 1-gram \t\t\tPrecision: 0.471\n",
      "Overlap 1-gram \t\t\tRecall: 0.634\n",
      "Overlap bi-gram \t\tF1: 0.635\n",
      "Overlap bi-gram \t\tPrecision: 0.546\n",
      "Overlap bi-gram \t\tRecall: 0.759\n",
      "Longest Common Subsequence \tF1: 0.254\n",
      "Longest Common Subsequence \tPrecision: 0.235\n",
      "Longest Common Subsequence \tRecall: 0.634\n",
      "\n",
      "FWSR-BM25\n",
      "Overlap 1-gram \t\t\tF1: 0.496\n",
      "Overlap 1-gram \t\t\tPrecision: 0.430\n",
      "Overlap 1-gram \t\t\tRecall: 0.586\n",
      "Overlap bi-gram \t\tF1: 0.590\n",
      "Overlap bi-gram \t\tPrecision: 0.497\n",
      "Overlap bi-gram \t\tRecall: 0.725\n",
      "Longest Common Subsequence \tF1: 0.195\n",
      "Longest Common Subsequence \tPrecision: 0.183\n",
      "Longest Common Subsequence \tRecall: 0.586\n",
      "\n",
      "FWSR-SIF\n",
      "Overlap 1-gram \t\t\tF1: 0.441\n",
      "Overlap 1-gram \t\t\tPrecision: 0.460\n",
      "Overlap 1-gram \t\t\tRecall: 0.424\n",
      "Overlap bi-gram \t\tF1: 0.562\n",
      "Overlap bi-gram \t\tPrecision: 0.562\n",
      "Overlap bi-gram \t\tRecall: 0.561\n",
      "Longest Common Subsequence \tF1: 0.391\n",
      "Longest Common Subsequence \tPrecision: 0.369\n",
      "Longest Common Subsequence \tRecall: 0.424\n",
      "CPU times: user 1min 50s, sys: 5.15 s, total: 1min 55s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "_ = extract_summary(doc, ref, title, report_rouge=True, rouge_embed=True, \n",
    "                    methods=methods, print_summary=False, print_rouge=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE Score Across Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = 5\n",
    "start = 0\n",
    "num_articles = 50\n",
    "#articles = source_text[start : start + num_articles]\n",
    "#references = source_refs[start : start + num_articles]\n",
    "#titles = source_titles[start : start + num_articles] if source_titles else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Mean ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first-k</th>\n",
       "      <th>SMRS</th>\n",
       "      <th>TextRank</th>\n",
       "      <th>FWSR-BM25</th>\n",
       "      <th>FWSR-SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.294351</td>\n",
       "      <td>0.112886</td>\n",
       "      <td>0.274215</td>\n",
       "      <td>0.243111</td>\n",
       "      <td>0.252973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.233306</td>\n",
       "      <td>0.112132</td>\n",
       "      <td>0.209661</td>\n",
       "      <td>0.176354</td>\n",
       "      <td>0.215249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.426295</td>\n",
       "      <td>0.129385</td>\n",
       "      <td>0.414050</td>\n",
       "      <td>0.407620</td>\n",
       "      <td>0.324946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.082003</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>0.077831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.079474</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>0.046395</td>\n",
       "      <td>0.065130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.155870</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.136162</td>\n",
       "      <td>0.114456</td>\n",
       "      <td>0.102587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.234303</td>\n",
       "      <td>0.095571</td>\n",
       "      <td>0.207752</td>\n",
       "      <td>0.175147</td>\n",
       "      <td>0.211727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>0.215461</td>\n",
       "      <td>0.105194</td>\n",
       "      <td>0.188953</td>\n",
       "      <td>0.159853</td>\n",
       "      <td>0.198332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.395592</td>\n",
       "      <td>0.118992</td>\n",
       "      <td>0.373967</td>\n",
       "      <td>0.369935</td>\n",
       "      <td>0.298449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.416465</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>85.040000</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>95.440000</td>\n",
       "      <td>105.540000</td>\n",
       "      <td>62.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            first-k       SMRS   TextRank   FWSR-BM25  \\\n",
       "1-gram F1                  0.294351   0.112886   0.274215    0.243111   \n",
       "1-gram Precision           0.233306   0.112132   0.209661    0.176354   \n",
       "1-gram Recall              0.426295   0.129385   0.414050    0.407620   \n",
       "bi-gram F1                 0.102360   0.011433   0.082003    0.065067   \n",
       "bi-gram Precision          0.079474   0.010627   0.060036    0.046395   \n",
       "bi-gram Recall             0.155870   0.013811   0.136162    0.114456   \n",
       "longest common F1          0.234303   0.095571   0.207752    0.175147   \n",
       "longest common Precision   0.215461   0.105194   0.188953    0.159853   \n",
       "longest common Recall      0.395592   0.118992   0.373967    0.369935   \n",
       "runtime                    0.000002   0.416465   0.008374    0.000676   \n",
       "word count                85.040000  46.660000  95.440000  105.540000   \n",
       "\n",
       "                           FWSR-SIF  \n",
       "1-gram F1                  0.252973  \n",
       "1-gram Precision           0.215249  \n",
       "1-gram Recall              0.324946  \n",
       "bi-gram F1                 0.077831  \n",
       "bi-gram Precision          0.065130  \n",
       "bi-gram Recall             0.102587  \n",
       "longest common F1          0.211727  \n",
       "longest common Precision   0.198332  \n",
       "longest common Recall      0.298449  \n",
       "runtime                    0.000767  \n",
       "word count                62.640000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Median =====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first-k</th>\n",
       "      <th>SMRS</th>\n",
       "      <th>TextRank</th>\n",
       "      <th>FWSR-BM25</th>\n",
       "      <th>FWSR-SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.121324</td>\n",
       "      <td>0.271007</td>\n",
       "      <td>0.255435</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.233093</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.203774</td>\n",
       "      <td>0.178453</td>\n",
       "      <td>0.218803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.410020</td>\n",
       "      <td>0.123724</td>\n",
       "      <td>0.418011</td>\n",
       "      <td>0.397368</td>\n",
       "      <td>0.345788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.079078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059289</td>\n",
       "      <td>0.057983</td>\n",
       "      <td>0.057983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046032</td>\n",
       "      <td>0.040294</td>\n",
       "      <td>0.054960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.118118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103191</td>\n",
       "      <td>0.100847</td>\n",
       "      <td>0.067033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.217275</td>\n",
       "      <td>0.093993</td>\n",
       "      <td>0.199213</td>\n",
       "      <td>0.173060</td>\n",
       "      <td>0.204430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>0.196154</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.182145</td>\n",
       "      <td>0.155870</td>\n",
       "      <td>0.185528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.376689</td>\n",
       "      <td>0.105296</td>\n",
       "      <td>0.356231</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.309402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.409360</td>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>77.500000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>61.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            first-k       SMRS   TextRank  FWSR-BM25  \\\n",
       "1-gram F1                  0.285714   0.121324   0.271007   0.255435   \n",
       "1-gram Precision           0.233093   0.111111   0.203774   0.178453   \n",
       "1-gram Recall              0.410020   0.123724   0.418011   0.397368   \n",
       "bi-gram F1                 0.079078   0.000000   0.059289   0.057983   \n",
       "bi-gram Precision          0.064583   0.000000   0.046032   0.040294   \n",
       "bi-gram Recall             0.118118   0.000000   0.103191   0.100847   \n",
       "longest common F1          0.217275   0.093993   0.199213   0.173060   \n",
       "longest common Precision   0.196154   0.100000   0.182145   0.155870   \n",
       "longest common Recall      0.376689   0.105296   0.356231   0.354839   \n",
       "runtime                    0.000002   0.409360   0.006971   0.000533   \n",
       "word count                77.500000  37.500000  90.500000  99.500000   \n",
       "\n",
       "                           FWSR-SIF  \n",
       "1-gram F1                  0.260870  \n",
       "1-gram Precision           0.218803  \n",
       "1-gram Recall              0.345788  \n",
       "bi-gram F1                 0.057983  \n",
       "bi-gram Precision          0.054960  \n",
       "bi-gram Recall             0.067033  \n",
       "longest common F1          0.204430  \n",
       "longest common Precision   0.185528  \n",
       "longest common Recall      0.309402  \n",
       "runtime                    0.000674  \n",
       "word count                61.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Standard Deviation ===============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first-k</th>\n",
       "      <th>SMRS</th>\n",
       "      <th>TextRank</th>\n",
       "      <th>FWSR-BM25</th>\n",
       "      <th>FWSR-SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>9.179386e-02</td>\n",
       "      <td>0.061925</td>\n",
       "      <td>0.075324</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.092870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>8.034488e-02</td>\n",
       "      <td>0.056874</td>\n",
       "      <td>0.062575</td>\n",
       "      <td>0.057610</td>\n",
       "      <td>0.079440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>1.456564e-01</td>\n",
       "      <td>0.090397</td>\n",
       "      <td>0.121346</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>0.133374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>8.803017e-02</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.068386</td>\n",
       "      <td>0.051503</td>\n",
       "      <td>0.071069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>6.902955e-02</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>1.372448e-01</td>\n",
       "      <td>0.031687</td>\n",
       "      <td>0.115417</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.101268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>8.795233e-02</td>\n",
       "      <td>0.052386</td>\n",
       "      <td>0.069108</td>\n",
       "      <td>0.058382</td>\n",
       "      <td>0.082450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>8.087494e-02</td>\n",
       "      <td>0.053474</td>\n",
       "      <td>0.061470</td>\n",
       "      <td>0.052118</td>\n",
       "      <td>0.075375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>1.458678e-01</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.114406</td>\n",
       "      <td>0.125185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>5.313258e-07</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>3.205618e+01</td>\n",
       "      <td>27.509715</td>\n",
       "      <td>31.206512</td>\n",
       "      <td>28.702759</td>\n",
       "      <td>19.817931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               first-k       SMRS   TextRank  FWSR-BM25  \\\n",
       "1-gram F1                 9.179386e-02   0.061925   0.075324   0.073689   \n",
       "1-gram Precision          8.034488e-02   0.056874   0.062575   0.057610   \n",
       "1-gram Recall             1.456564e-01   0.090397   0.121346   0.125786   \n",
       "bi-gram F1                8.803017e-02   0.026728   0.068386   0.051503   \n",
       "bi-gram Precision         6.902955e-02   0.026159   0.050387   0.037592   \n",
       "bi-gram Recall            1.372448e-01   0.031687   0.115417   0.087262   \n",
       "longest common F1         8.795233e-02   0.052386   0.069108   0.058382   \n",
       "longest common Precision  8.087494e-02   0.053474   0.061470   0.052118   \n",
       "longest common Recall     1.458678e-01   0.079670   0.122362   0.114406   \n",
       "runtime                   5.313258e-07   0.044452   0.004674   0.000748   \n",
       "word count                3.205618e+01  27.509715  31.206512  28.702759   \n",
       "\n",
       "                           FWSR-SIF  \n",
       "1-gram F1                  0.092870  \n",
       "1-gram Precision           0.079440  \n",
       "1-gram Recall              0.133374  \n",
       "bi-gram F1                 0.071069  \n",
       "bi-gram Precision          0.057738  \n",
       "bi-gram Recall             0.101268  \n",
       "longest common F1          0.082450  \n",
       "longest common Precision   0.075375  \n",
       "longest common Recall      0.125185  \n",
       "runtime                    0.000293  \n",
       "word count                19.817931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 54s, sys: 27 s, total: 6min 21s\n",
      "Wall time: 8min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "rouge_mean, rouge_median, rouge_std = report_rouge_scores(source_text[start : start + num_articles], \n",
    "                                                          source_refs[start : start + num_articles], \n",
    "                                                          methods=methods)\n",
    "\n",
    "index =  ['1-gram F1', '1-gram Precision', '1-gram Recall', 'bi-gram F1', 'bi-gram Precision', 'bi-gram Recall', \n",
    "          'longest common F1', 'longest common Precision', 'longest common Recall', 'runtime', 'word count']\n",
    "\n",
    "print('=' * 22 + ' Mean ' + '=' * 22)\n",
    "rouge_mean.index = index\n",
    "display(rouge_mean)\n",
    "\n",
    "print('=' * 21 + ' Median ' + '=' * 21)\n",
    "rouge_median.index = index\n",
    "display(rouge_median)\n",
    "\n",
    "print('=' * 15 + ' Standard Deviation ' + '=' * 15)\n",
    "rouge_std.index = index\n",
    "display(rouge_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_mean.to_csv('cnn_lexical_rouge_mean_50.csv', index=False)\n",
    "rouge_median.to_csv('cnn_lexical_rouge_median_50.csv', index=False)\n",
    "rouge_std.to_csv('cnn_lexical_rouge_std_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding ROUGE Score Across Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "rouge_mean_embed, rouge_median_embed, rouge_std_embed = report_rouge_scores(source_text[start : start + num_articles], \n",
    "                                                                            source_refs[start : start + num_articles],  \n",
    "                                                                            rouge_embed=True, methods=methods)\n",
    "\n",
    "index =  ['1-gram F1', '1-gram Precision', '1-gram Recall', 'bi-gram F1', 'bi-gram Precision', 'bi-gram Recall', \n",
    "          'longest common F1', 'longest common Precision', 'longest common Recall', 'runtime', 'word count']\n",
    "\n",
    "print('=' * 22 + ' Mean ' + '=' * 22)\n",
    "rouge_mean_embed.index = index\n",
    "display(rouge_mean_embed)\n",
    "\n",
    "print('=' * 21 + ' Median ' + '=' * 21)\n",
    "rouge_median_embed.index = index\n",
    "display(rouge_median_embed)\n",
    "\n",
    "print('=' * 15 + ' Standard Deviation ' + '=' * 15)\n",
    "rouge_std_embed.index = index\n",
    "display(rouge_std_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_mean.to_csv('cnn_semantic_rouge_mean_50.csv', index=False)\n",
    "rouge_median.to_csv('cnn_semantic_rouge_median_50.csv', index=False)\n",
    "rouge_std.to_csv('cnn_semantic_rouge_std_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicago wins bid for new george lucas museum. mayor rahm emanuel calls it \"a milestone\" for his city. lucas says a prime location in chicago was a deciding factor. museum will house lucas\\' art collection and movie memorabilia.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
