{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data\n",
    "import utils\n",
    "from main import extract_summary, report_rouge_scores\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Get list of titles, reference summaries, and body text\n",
    "source_titles, source_refs, source_text = data.get_classical_book_data(num=30)\n",
    "print(len(source_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "doc_idx = 3\n",
    "doc = source_text[doc_idx]\n",
    "ref = source_refs[doc_idx]\n",
    "title = source_titles[doc_idx] if source_titles else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soruce Text: 28 sentences, 144 distinct vocab\n",
      "# of selected sentences: 3\n",
      "=============== Referecne Text ==============\n",
      "the \"defeat jihad\" ad is displayed in several new york subway stations. jewish and christian groups buy new ads, touting religious tolerance. some are already up; others go up on monday.\n",
      "-----\n",
      "Word count:31\n",
      "\n",
      "========== Extracted summary: First k ==========\n",
      "New york  -- jewish and christian groups have unveiled three separate ad campaigns to counter what they claim is hateful speech toward muslims contained within an advertisement posted at some new york city subway stations.\n",
      "The new ads tout religious tolerance and offer support to the muslim community.\n",
      "\"help stop bigotry against our muslim neighbors,\" reads one.\n",
      "-----\n",
      "Word count:57\n",
      "First_k selection computation time: 0.000\n",
      "\n",
      "========== Extracted summary: SMRS ==========\n",
      "They are confusing resistance to hatred with actual hatred.\".\n",
      "Cnn's erinn cawthon contributed to this report.\n",
      "Regarding her critics, geller said: \"their moral myopia is immense.\n",
      "-----\n",
      "Word count:26\n",
      "SMRS computation time: 0.375\n",
      "\n",
      "========== Extracted summary: TextRank ==========\n",
      "new york  -- jewish and christian groups have unveiled three separate ad campaigns to counter what they claim is hateful speech toward muslims contained within an advertisement posted at some new york city subway stations.\n",
      "the campaigns are in response to a controversial \"defeat jihad\" ad that is displayed in 10 of the city's more than 400 subway stations.\n",
      "\"we, as an organization of rabbis want to make it clear to new york and to the u.s. that neither rabbis nor the mainstream jewish community support this dehumanization, but in fact we value partnership with our muslim neighbors and muslim organizations,\" said rabbi jill jacobs, of rabbis for human rights, one of the three groups behind the new ads.\n",
      "Word count: 119\n",
      "TextRank computation time: 0.006\n",
      "\n",
      "========== Extracted summary: FWSR-BM25 ==========\n",
      "New york  -- jewish and christian groups have unveiled three separate ad campaigns to counter what they claim is hateful speech toward muslims contained within an advertisement posted at some new york city subway stations.\n",
      "\"we, as an organization of rabbis want to make it clear to new york and to the u.s. that neither rabbis nor the mainstream jewish community support this dehumanization, but in fact we value partnership with our muslim neighbors and muslim organizations,\" said rabbi jill jacobs, of rabbis for human rights, one of the three groups behind the new ads.\n",
      "Meanwhile, pamela geller, executive director of the american freedom defense initiative, defended the controversial \"defeat jihad\" ad, saying there is nothing hateful about it.\n",
      "-----\n",
      "Word count:119\n",
      "FWSR-BM25 computation time: 0.001\n",
      "\n",
      "====== Extracted summary: FWSR-SIF ======\n",
      "Sentence embedding shape: (28, 300)\n",
      "New york  -- jewish and christian groups have unveiled three separate ad campaigns to counter what they claim is hateful speech toward muslims contained within an advertisement posted at some new york city subway stations.\n",
      "Defeat jihad.\".\n",
      "Jacobs described an outpouring of support from individual donors in response to the \"defeat jihad\" ad, which allowed for the purchase of 20 new ads.\n",
      "-----\n",
      "Word count:62\n",
      "FWSR-SIF computation time: 0.001\n",
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "first-k\n",
      "Overlap 1-gram \t\t\tF1: 0.341\n",
      "Overlap 1-gram \t\t\tPrecision: 0.269\n",
      "Overlap 1-gram \t\t\tRecall: 0.467\n",
      "Overlap bi-gram \t\tF1: 0.140\n",
      "Overlap bi-gram \t\tPrecision: 0.107\n",
      "Overlap bi-gram \t\tRecall: 0.200\n",
      "Longest Common Subsequence \tF1: 0.280\n",
      "Longest Common Subsequence \tPrecision: 0.250\n",
      "Longest Common Subsequence \tRecall: 0.433\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.073\n",
      "Overlap 1-gram \t\t\tPrecision: 0.080\n",
      "Overlap 1-gram \t\t\tRecall: 0.067\n",
      "Overlap bi-gram \t\tF1: 0.000\n",
      "Overlap bi-gram \t\tPrecision: 0.000\n",
      "Overlap bi-gram \t\tRecall: 0.000\n",
      "Longest Common Subsequence \tF1: 0.072\n",
      "Longest Common Subsequence \tPrecision: 0.080\n",
      "Longest Common Subsequence \tRecall: 0.067\n",
      "\n",
      "TextRank\n",
      "Overlap 1-gram \t\t\tF1: 0.293\n",
      "Overlap 1-gram \t\t\tPrecision: 0.198\n",
      "Overlap 1-gram \t\t\tRecall: 0.567\n",
      "Overlap bi-gram \t\tF1: 0.125\n",
      "Overlap bi-gram \t\tPrecision: 0.079\n",
      "Overlap bi-gram \t\tRecall: 0.300\n",
      "Longest Common Subsequence \tF1: 0.213\n",
      "Longest Common Subsequence \tPrecision: 0.198\n",
      "Longest Common Subsequence \tRecall: 0.567\n",
      "\n",
      "FWSR-BM25\n",
      "Overlap 1-gram \t\t\tF1: 0.244\n",
      "Overlap 1-gram \t\t\tPrecision: 0.161\n",
      "Overlap 1-gram \t\t\tRecall: 0.500\n",
      "Overlap bi-gram \t\tF1: 0.082\n",
      "Overlap bi-gram \t\tPrecision: 0.052\n",
      "Overlap bi-gram \t\tRecall: 0.200\n",
      "Longest Common Subsequence \tF1: 0.172\n",
      "Longest Common Subsequence \tPrecision: 0.161\n",
      "Longest Common Subsequence \tRecall: 0.500\n",
      "\n",
      "FWSR-SIF\n",
      "Overlap 1-gram \t\t\tF1: 0.345\n",
      "Overlap 1-gram \t\t\tPrecision: 0.263\n",
      "Overlap 1-gram \t\t\tRecall: 0.500\n",
      "Overlap bi-gram \t\tF1: 0.152\n",
      "Overlap bi-gram \t\tPrecision: 0.113\n",
      "Overlap bi-gram \t\tRecall: 0.233\n",
      "Longest Common Subsequence \tF1: 0.274\n",
      "Longest Common Subsequence \tPrecision: 0.246\n",
      "Longest Common Subsequence \tRecall: 0.467\n"
     ]
    }
   ],
   "source": [
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "extract_summary(doc, ref, title, report_rouge=True, print_rouge=True, methods=methods, print_summary=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "first-k\n",
      "Overlap 1-gram \t\t\tF1: 0.341\n",
      "Overlap 1-gram \t\t\tPrecision: 0.269\n",
      "Overlap 1-gram \t\t\tRecall: 0.467\n",
      "Overlap bi-gram \t\tF1: 0.140\n",
      "Overlap bi-gram \t\tPrecision: 0.107\n",
      "Overlap bi-gram \t\tRecall: 0.200\n",
      "Longest Common Subsequence \tF1: 0.280\n",
      "Longest Common Subsequence \tPrecision: 0.250\n",
      "Longest Common Subsequence \tRecall: 0.433\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.073\n",
      "Overlap 1-gram \t\t\tPrecision: 0.080\n",
      "Overlap 1-gram \t\t\tRecall: 0.067\n",
      "Overlap bi-gram \t\tF1: 0.000\n",
      "Overlap bi-gram \t\tPrecision: 0.000\n",
      "Overlap bi-gram \t\tRecall: 0.000\n",
      "Longest Common Subsequence \tF1: 0.072\n",
      "Longest Common Subsequence \tPrecision: 0.080\n",
      "Longest Common Subsequence \tRecall: 0.067\n",
      "\n",
      "TextRank\n",
      "Overlap 1-gram \t\t\tF1: 0.293\n",
      "Overlap 1-gram \t\t\tPrecision: 0.198\n",
      "Overlap 1-gram \t\t\tRecall: 0.567\n",
      "Overlap bi-gram \t\tF1: 0.125\n",
      "Overlap bi-gram \t\tPrecision: 0.079\n",
      "Overlap bi-gram \t\tRecall: 0.300\n",
      "Longest Common Subsequence \tF1: 0.213\n",
      "Longest Common Subsequence \tPrecision: 0.198\n",
      "Longest Common Subsequence \tRecall: 0.567\n",
      "\n",
      "FWSR-BM25\n",
      "Overlap 1-gram \t\t\tF1: 0.244\n",
      "Overlap 1-gram \t\t\tPrecision: 0.161\n",
      "Overlap 1-gram \t\t\tRecall: 0.500\n",
      "Overlap bi-gram \t\tF1: 0.082\n",
      "Overlap bi-gram \t\tPrecision: 0.052\n",
      "Overlap bi-gram \t\tRecall: 0.200\n",
      "Longest Common Subsequence \tF1: 0.172\n",
      "Longest Common Subsequence \tPrecision: 0.161\n",
      "Longest Common Subsequence \tRecall: 0.500\n",
      "\n",
      "FWSR-SIF\n",
      "Overlap 1-gram \t\t\tF1: 0.345\n",
      "Overlap 1-gram \t\t\tPrecision: 0.263\n",
      "Overlap 1-gram \t\t\tRecall: 0.500\n",
      "Overlap bi-gram \t\tF1: 0.152\n",
      "Overlap bi-gram \t\tPrecision: 0.113\n",
      "Overlap bi-gram \t\tRecall: 0.233\n",
      "Longest Common Subsequence \tF1: 0.274\n",
      "Longest Common Subsequence \tPrecision: 0.246\n",
      "Longest Common Subsequence \tRecall: 0.467\n",
      "CPU times: user 6.77 s, sys: 459 ms, total: 7.23 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k=5\n",
    "# ratio=0.3\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "extract_summary(doc, ref, title, report_rouge=True, rouge_embed=False, \n",
    "                methods=methods, print_summary=False, print_rouge=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Word Embedding ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== ROUGE Scores ===============\n",
      "\n",
      "first-k\n",
      "Overlap 1-gram \t\t\tF1: 0.529\n",
      "Overlap 1-gram \t\t\tPrecision: 0.454\n",
      "Overlap 1-gram \t\t\tRecall: 0.634\n",
      "Overlap bi-gram \t\tF1: 0.627\n",
      "Overlap bi-gram \t\tPrecision: 0.541\n",
      "Overlap bi-gram \t\tRecall: 0.744\n",
      "Longest Common Subsequence \tF1: 0.289\n",
      "Longest Common Subsequence \tPrecision: 0.264\n",
      "Longest Common Subsequence \tRecall: 0.634\n",
      "\n",
      "SMRS\n",
      "Overlap 1-gram \t\t\tF1: 0.333\n",
      "Overlap 1-gram \t\t\tPrecision: 0.311\n",
      "Overlap 1-gram \t\t\tRecall: 0.358\n",
      "Overlap bi-gram \t\tF1: 0.497\n",
      "Overlap bi-gram \t\tPrecision: 0.489\n",
      "Overlap bi-gram \t\tRecall: 0.505\n",
      "Longest Common Subsequence \tF1: 0.274\n",
      "Longest Common Subsequence \tPrecision: 0.247\n",
      "Longest Common Subsequence \tRecall: 0.358\n",
      "\n",
      "TextRank\n",
      "Overlap 1-gram \t\t\tF1: 0.541\n",
      "Overlap 1-gram \t\t\tPrecision: 0.471\n",
      "Overlap 1-gram \t\t\tRecall: 0.634\n",
      "Overlap bi-gram \t\tF1: 0.635\n",
      "Overlap bi-gram \t\tPrecision: 0.546\n",
      "Overlap bi-gram \t\tRecall: 0.759\n",
      "Longest Common Subsequence \tF1: 0.254\n",
      "Longest Common Subsequence \tPrecision: 0.235\n",
      "Longest Common Subsequence \tRecall: 0.634\n",
      "\n",
      "FWSR-BM25\n",
      "Overlap 1-gram \t\t\tF1: 0.496\n",
      "Overlap 1-gram \t\t\tPrecision: 0.430\n",
      "Overlap 1-gram \t\t\tRecall: 0.586\n",
      "Overlap bi-gram \t\tF1: 0.590\n",
      "Overlap bi-gram \t\tPrecision: 0.497\n",
      "Overlap bi-gram \t\tRecall: 0.725\n",
      "Longest Common Subsequence \tF1: 0.195\n",
      "Longest Common Subsequence \tPrecision: 0.183\n",
      "Longest Common Subsequence \tRecall: 0.586\n",
      "\n",
      "FWSR-SIF\n",
      "Overlap 1-gram \t\t\tF1: 0.441\n",
      "Overlap 1-gram \t\t\tPrecision: 0.460\n",
      "Overlap 1-gram \t\t\tRecall: 0.424\n",
      "Overlap bi-gram \t\tF1: 0.562\n",
      "Overlap bi-gram \t\tPrecision: 0.562\n",
      "Overlap bi-gram \t\tRecall: 0.561\n",
      "Longest Common Subsequence \tF1: 0.391\n",
      "Longest Common Subsequence \tPrecision: 0.369\n",
      "Longest Common Subsequence \tRecall: 0.424\n",
      "CPU times: user 1min 50s, sys: 5.15 s, total: 1min 55s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "_ = extract_summary(doc, ref, title, report_rouge=True, rouge_embed=True, \n",
    "                    methods=methods, print_summary=False, print_rouge=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE Score Across Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = 5\n",
    "start = 0\n",
    "num_articles = 20\n",
    "#articles = source_text[start : start + num_articles]\n",
    "#references = source_refs[start : start + num_articles]\n",
    "#titles = source_titles[start : start + num_articles] if source_titles else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Mean ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FWSR-SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.165775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.204539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.149550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.012418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.016742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.011250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.131793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>0.181518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.130519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.015308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>84.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FWSR-SIF\n",
       "1-gram F1                  0.165775\n",
       "1-gram Precision           0.204539\n",
       "1-gram Recall              0.149550\n",
       "bi-gram F1                 0.012418\n",
       "bi-gram Precision          0.016742\n",
       "bi-gram Recall             0.011250\n",
       "longest common F1          0.131793\n",
       "longest common Precision   0.181518\n",
       "longest common Recall      0.130519\n",
       "runtime                    0.015308\n",
       "word count                84.250000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Median =====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FWSR-SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.148822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.189495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.120766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.012969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.017170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.010291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.121088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>0.163969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.116240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.011192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>78.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FWSR-SIF\n",
       "1-gram F1                  0.148822\n",
       "1-gram Precision           0.189495\n",
       "1-gram Recall              0.120766\n",
       "bi-gram F1                 0.012969\n",
       "bi-gram Precision          0.017170\n",
       "bi-gram Recall             0.010291\n",
       "longest common F1          0.121088\n",
       "longest common Precision   0.163969\n",
       "longest common Recall      0.116240\n",
       "runtime                    0.011192\n",
       "word count                78.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Standard Deviation ===============\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FWSR-SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-gram F1</th>\n",
       "      <td>0.051250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Precision</th>\n",
       "      <td>0.063745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-gram Recall</th>\n",
       "      <td>0.064731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram F1</th>\n",
       "      <td>0.012073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Precision</th>\n",
       "      <td>0.016314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi-gram Recall</th>\n",
       "      <td>0.012406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common F1</th>\n",
       "      <td>0.040941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Precision</th>\n",
       "      <td>0.057892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longest common Recall</th>\n",
       "      <td>0.051526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>0.013322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word count</th>\n",
       "      <td>46.030289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FWSR-SIF\n",
       "1-gram F1                  0.051250\n",
       "1-gram Precision           0.063745\n",
       "1-gram Recall              0.064731\n",
       "bi-gram F1                 0.012073\n",
       "bi-gram Precision          0.016314\n",
       "bi-gram Recall             0.012406\n",
       "longest common F1          0.040941\n",
       "longest common Precision   0.057892\n",
       "longest common Recall      0.051526\n",
       "runtime                    0.013322\n",
       "word count                46.030289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 32s, sys: 10.7 s, total: 4min 43s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "methods = ['FWSR-SIF']#['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "rouge_mean, rouge_median, rouge_std = report_rouge_scores(source_text[start : start + num_articles], \n",
    "                                                          source_refs[start : start + num_articles], \n",
    "                                                          methods=methods)\n",
    "\n",
    "index =  ['1-gram F1', '1-gram Precision', '1-gram Recall', 'bi-gram F1', 'bi-gram Precision', 'bi-gram Recall', \n",
    "          'longest common F1', 'longest common Precision', 'longest common Recall', 'runtime', 'word count']\n",
    "\n",
    "print('=' * 22 + ' Mean ' + '=' * 22)\n",
    "rouge_mean.index = index\n",
    "display(rouge_mean)\n",
    "\n",
    "print('=' * 21 + ' Median ' + '=' * 21)\n",
    "rouge_median.index = index\n",
    "display(rouge_median)\n",
    "\n",
    "print('=' * 15 + ' Standard Deviation ' + '=' * 15)\n",
    "rouge_std.index = index\n",
    "display(rouge_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_mean.to_csv('books_lexical_rouge_mean_44.csv', index=False)\n",
    "rouge_median.to_csv('books_lexical_rouge_median_44.csv', index=False)\n",
    "rouge_std.to_csv('books_lexical_rouge_std_44.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding ROUGE Score Across Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "methods = ['first-k', 'SMRS', 'TextRank', 'FWSR-BM25', 'FWSR-SIF']\n",
    "rouge_mean_embed, rouge_median_embed, rouge_std_embed = report_rouge_scores(source_text[start : start + num_articles], \n",
    "                                                                            source_refs[start : start + num_articles],  \n",
    "                                                                            rouge_embed=True, methods=methods)\n",
    "\n",
    "index =  ['1-gram F1', '1-gram Precision', '1-gram Recall', 'bi-gram F1', 'bi-gram Precision', 'bi-gram Recall', \n",
    "          'longest common F1', 'longest common Precision', 'longest common Recall', 'runtime', 'word count']\n",
    "\n",
    "print('=' * 22 + ' Mean ' + '=' * 22)\n",
    "rouge_mean_embed.index = index\n",
    "display(rouge_mean_embed)\n",
    "\n",
    "print('=' * 21 + ' Median ' + '=' * 21)\n",
    "rouge_median_embed.index = index\n",
    "display(rouge_median_embed)\n",
    "\n",
    "print('=' * 15 + ' Standard Deviation ' + '=' * 15)\n",
    "rouge_std_embed.index = index\n",
    "display(rouge_std_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_mean.to_csv('cnn_semantic_rouge_mean_50.csv', index=False)\n",
    "rouge_median.to_csv('cnn_semantic_rouge_median_50.csv', index=False)\n",
    "rouge_std.to_csv('cnn_semantic_rouge_std_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicago wins bid for new george lucas museum. mayor rahm emanuel calls it \"a milestone\" for his city. lucas says a prime location in chicago was a deciding factor. museum will house lucas\\' art collection and movie memorabilia.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
