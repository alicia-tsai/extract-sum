{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os. path import join\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '../data/aligned-summarization-data/eacl_sample_full/annotator_a/alignments/'\n",
    "narrative_path = '../data/aligned-summarization-data/eacl_sample_full/narrative/'\n",
    "files = listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "refs, text = [], []\n",
    "for file in files:\n",
    "    with open(join(path, file), encoding='utf-8') as f:\n",
    "        try:\n",
    "            lines = f.readlines()\n",
    "            refs.append(lines[1].replace('\\n', '').replace('EXTRACTIVE: ', '').replace('[[', '').replace(']]', ''))\n",
    "            # get source text\n",
    "            with open(join(narrative_path, file[:-10] + 'story')) as source_f:\n",
    "                source_text = ' '.join(source_f.readlines())\n",
    "                text.append(source_text.replace('\\n', ''))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lines[1].replace('\\n', '').replace('EXTRACTIVE: ', '').replace('[[', '').replace(']]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(join(narrative_path, files[0][:-10] + 'story')) as ff:\n",
    "    ll = ff.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['reference'] = refs\n",
    "data['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('reddit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN/ Daily News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_path = '../data/cnn_stories/cnn/stories/'\n",
    "dailymail_path = '../data/dailymail_stories/dailymail/stories/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_cnn_daily(line):\n",
    "    \"\"\"Clean text for CNN/Daily mail dataset.\"\"\"\n",
    "    line = line.lower()\n",
    "    line = line.replace('\\n', '').replace('(cnn)', '')\n",
    "    if \"@highlight\" in line: return line\n",
    "    if line != \"\":\n",
    "        # fix missing period\n",
    "        if line[-1] not in ['.', '?', '!']:\n",
    "            return line + \".\"\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = listdir(dailymail_path)\n",
    "refs, text = [], []\n",
    "for file in files:\n",
    "    with open(join(dailymail_path, file), encoding='utf-8') as f:\n",
    "        try:\n",
    "            lines = f.readlines()\n",
    "            body_text = []\n",
    "            reference = []\n",
    "            next_is_highlight = False\n",
    "            for line in lines:\n",
    "                line = clean_text_cnn_daily(line)\n",
    "                if line == '':  # empty\n",
    "                    continue\n",
    "                elif line.startswith('@highlight'):\n",
    "                    next_is_highlight = True\n",
    "                elif next_is_highlight:\n",
    "                    reference.append(line)\n",
    "                else:\n",
    "                    body_text.append(line)\n",
    "            \n",
    "            # Make body text and reference into a single string\n",
    "            text.append(' '.join(body_text))\n",
    "            refs.append(' '.join(reference))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_dataframe(text, refs):\n",
    "    data = pd.DataFrame()\n",
    "    data['text'] = text\n",
    "    data['reference'] = refs\n",
    "    data = data[~data.duplicated()]\n",
    "    data = data[data.text != '']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = save_to_dataframe(text, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the bbc has apologised after john inverdale ma...</td>\n",
       "      <td>presenter john inverdale said 'rose-c*****' gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>denver quarterback peyton manning broke brett ...</td>\n",
       "      <td>denver quarterback peyton manning reached 510 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>by . michael seamark. updated:. 05:47 est, 8 f...</td>\n",
       "      <td>gary mckinnon's family battling against his ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norwich city have taken the unexpected decisio...</td>\n",
       "      <td>neil adams appointed as norwich city's new man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>becky edwards from cannock, staffs. was so hum...</td>\n",
       "      <td>becky edwards from cannock, staffs. was so hum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  the bbc has apologised after john inverdale ma...   \n",
       "1  denver quarterback peyton manning broke brett ...   \n",
       "2  by . michael seamark. updated:. 05:47 est, 8 f...   \n",
       "3  norwich city have taken the unexpected decisio...   \n",
       "4  becky edwards from cannock, staffs. was so hum...   \n",
       "\n",
       "                                           reference  \n",
       "0  presenter john inverdale said 'rose-c*****' gl...  \n",
       "1  denver quarterback peyton manning reached 510 ...  \n",
       "2  gary mckinnon's family battling against his ex...  \n",
       "3  neil adams appointed as norwich city's new man...  \n",
       "4  becky edwards from cannock, staffs. was so hum...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/dailymail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
